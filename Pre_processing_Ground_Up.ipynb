{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to start a ground  u p rework fothe data based on features suggested by our favourite co-pilot. It seems like we can get a decent answer based on a lightweight model, by processing the audio files using librosa. The features we're lookoing to extract are: Mel-Frequency Cepstral Coefficients(MFCC) \n",
    "Specra Centroid\n",
    "Specral Bandwidth\n",
    "Specral Flatness\n",
    "Spectral Contrast\n",
    "Time Domain features - Zero Crossing rate (ZCR)\n",
    "Root Mean Square Energy (RMSE)\n",
    "Temporal features - Short-time energy\n",
    "Tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips for Efficient Processing on Raspberry Pi 5\n",
    "\n",
    "    Downsampling:\n",
    "        Use a lower sampling rate (e.g., 16 kHz) unless high-frequency information is crucial.\n",
    "    Windowing:\n",
    "        Apply short-time Fourier transform (STFT) with small windows (e.g., 20â€“50 ms) for manageable computational loads.\n",
    "    Batch Processing:\n",
    "        Process audio in chunks to avoid memory and CPU spikes.\n",
    "    Feature Dimensionality Reduction:\n",
    "        Reduce the number of features using techniques like Principal Component Analysis (PCA) after extraction.\n",
    "    Quantized Models:\n",
    "        Use a lightweight, quantized ML model optimized for edge devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import basic pacages for data processing . We're going to use Librosa to process the data as it seems to be  more lightweight than alternatives.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of audio, we are resampling, normalising and trimming silence.\n",
    "\n",
    "Resampling will normalise the sampling rate, reducing one variable between datasets. I assume this means that we will want to resamle audio in the input stream.\n",
    "\n",
    "Normalise standardises the audio amplitude, apparently mimising the influence of recording volume, to prevent outlier high or low sounds from affecting the  model training. \n",
    "\n",
    "Trimming silence to remove useless pieces of data to save on computation, and reduce the affect silence could have on affecting our model weights. (Need to check this, feel like it should be heavily caveated.) I have now checked this, it makes sense that silence being a recurring feature across classes could lead to issues, but having a separate class specifically for silence callsed (no event) would be good potentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to start with a single wav file as a test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestAudioPath = \"audio/fold1/7061-6-0-0.wav\"\n",
    "\n",
    "def extract_features(file_path, sr=16000, n_mfcc=13):\n",
    "    # Load the audio file\n",
    "    audio, sample_rate = librosa.load(TestAudioPath, sr=sr)\n",
    "\n",
    "    # Extract the MFCC features\n",
    "    mfccs = librosa.features.mfcc(y=aduio, sr=sample_rate, n_mfcc = n_mfcc)\n",
    "\n",
    "    # Compute the mean of the extracted features across  frames\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "\n",
    "    #TODO: This still needs to be finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've questioned chatgpt on why it wants  to normalise the MFCCs to a human frequency (using the mel scale.) It has agreed this doesnt really make sense. I think I will try to go down the path of doing both mel scale and none mel scale feature sets, build a model from both and see how they compare. Potentially may be worth stacking them? I don't see how applying a log scale is going to help much though..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectral_features(audio, sr):\n",
    "    # Short-Time Fourier Transform (STFT)\n",
    "    stft = np.abs(librosa.stft(audio))\n",
    "    \n",
    "    # Spectral Features\n",
    "    centroid = np.mean(librosa.feature.spectral_centroid(S=stft, sr=sr))\n",
    "    bandwidth = np.mean(librosa.feature.spectral_bandwidth(S=stft, sr=sr))\n",
    "    flatness = np.mean(librosa.feature.spectral_flatness(S=stft))\n",
    "    \n",
    "    # Temporal Features\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "    peak_amplitude = np.max(np.abs(audio))\n",
    "    \n",
    "    # Combine features\n",
    "    features = [centroid, bandwidth, flatness, peak_amplitude]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
